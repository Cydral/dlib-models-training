# Dlib Model Training Toolkit

## Universal Dlib Training Pipelines

This repository provides modular training c++ programs for:
- âœ… Any Dlib-compatible model architecture
- âœ… Any image dataset (including custom datasets)
- âœ… Multiple training scenarios (from scratch/fine-tuning)

## `dnn_Vision_Transformer_SSL_ex.cpp`

**Description**:  
Implements a Vision Transformer (ViT) trained using Barlow Twins self-supervised learning on CIFAR-10. This example demonstrates:

- ğŸ§  Pure transformer architecture for computer vision
- ğŸ” Self-supervised pretraining (no labels needed)

**Key Features**:
- Modular ViT architecture configurable for different:
  - Patch sizes
  - Attention heads
  - Transformer layers
- Barlow Twins loss for redundancy reduction
- Integrated evaluation with multiclass SVM
